{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c71f3494",
   "metadata": {},
   "source": [
    "# Stock Market Prediction Project\n",
    "\n",
    "## Introduction\n",
    "This notebook presents our analysis and implementation of machine learning models for stock price prediction. We'll use historical data from Apple (AAPL) stock to predict future stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7f31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Import our modules\n",
    "from src.data_loader import load_stock_data, prepare_data_for_training, plot_stock_data\n",
    "from src.models import (\n",
    "    LinearRegressionModel,\n",
    "    RandomForestModel, \n",
    "    LSTMModel,\n",
    "    plot_predictions,\n",
    "    plot_training_history, \n",
    "    compare_models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08ef4a",
   "metadata": {},
   "source": [
    "## 1. Literature Review\n",
    "\n",
    "### Related Studies on Stock Price Prediction\n",
    "\n",
    "1. **Efficient Market Hypothesis and its Challenges**\n",
    "   - Fama, E.F. (1970). \"Efficient Capital Markets: A Review of Theory and Empirical Work.\" The Journal of Finance, 25(2), 383-417.\n",
    "   - The efficient market hypothesis (EMH) suggests that stock prices reflect all available information, making prediction impossible. However, recent studies have challenged this hypothesis using machine learning techniques.\n",
    "\n",
    "2. **Machine Learning Approaches for Stock Prediction**\n",
    "   - Patel, J., Shah, S., Thakkar, P., & Kotecha, K. (2015). \"Predicting stock market index using fusion of machine learning techniques.\" Expert Systems with Applications, 42(4), 2162-2172.\n",
    "   - This study compared various machine learning algorithms including Random Forest, Support Vector Machines, and Neural Networks for stock market prediction and found that Random Forest often performed well for short-term predictions.\n",
    "\n",
    "3. **Deep Learning Applications in Financial Time Series**\n",
    "   - Fischer, T., & Krauss, C. (2018). \"Deep learning with long short-term memory networks for financial market predictions.\" European Journal of Operational Research, 270(2), 654-669.\n",
    "   - This research demonstrated that LSTM neural networks can effectively capture temporal dependencies in financial time series data, often outperforming traditional methods.\n",
    "   \n",
    "4. **Feature Engineering for Stock Prediction**\n",
    "   - Sezer, O.B., Gudelek, M.U., & Ozbayoglu, A.M. (2020). \"Financial time series forecasting with deep learning: A systematic literature review: 2005-2019.\" Applied Soft Computing, 90, 106181.\n",
    "   - This comprehensive review discusses the importance of feature engineering in stock prediction models and various approaches to select the most relevant features.\n",
    "\n",
    "Our project builds upon these studies, implementing and comparing both traditional machine learning models (Linear Regression, Random Forest) and neural network approaches for stock price prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a1bff",
   "metadata": {},
   "source": [
    "## 2. Loading and Visualizing Stock Data\n",
    "\n",
    "We'll start by loading Apple (AAPL) stock data using yfinance and visualizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Apple stock data\n",
    "ticker = 'AAPL'\n",
    "data = load_stock_data(ticker=ticker)\n",
    "\n",
    "# Display the first few rows\n",
    "print(f\"Loaded {len(data)} rows of {ticker} stock data\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e61584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the stock price history\n",
    "plot_stock_data(data, title=f\"{ticker} Stock Price History\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aebca72",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "We'll prepare our data for training by:\n",
    "1. Normalizing the data\n",
    "2. Creating sequences for time-series prediction\n",
    "3. Splitting into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f951f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "sequence_length = 60  # Use 60 days of data to predict the next day\n",
    "X_train, y_train, X_test, y_test, scaler = prepare_data_for_training(\n",
    "    data, target_column='Close', sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9aa99",
   "metadata": {},
   "source": [
    "## 4. Machine Learning Models\n",
    "\n",
    "We'll implement and compare three different models for stock price prediction:\n",
    "\n",
    "1. Linear Regression\n",
    "2. Random Forest\n",
    "3. Neural Network (MLPRegressor as a substitute for LSTM)\n",
    "\n",
    "### 4.1 Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Linear Regression model\n",
    "lr_model = LinearRegressionModel()\n",
    "lr_model.train(X_train, y_train)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestModel(n_estimators=100, max_depth=20)\n",
    "rf_model.train(X_train, y_train)\n",
    "\n",
    "# Train Neural Network model\n",
    "nn_model = LSTMModel(input_shape=(X_train.shape[1], 1), units=50)\n",
    "nn_model.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89680c5",
   "metadata": {},
   "source": [
    "### 4.2 Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37011e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "models = [lr_model, rf_model, nn_model]\n",
    "comparison_df = compare_models(models, X_test, y_test)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss for Neural Network model\n",
    "if nn_model.history is not None:\n",
    "    plot_training_history(nn_model.history, title=\"Neural Network Training Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f719559",
   "metadata": {},
   "source": [
    "### 4.3 Feature Importance Analysis\n",
    "For the Random Forest model, we can analyze which days in our 60-day sequence are most important for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6aaf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for Random Forest model\n",
    "if hasattr(rf_model.model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Day': [f'Day-{i+1}' for i in range(sequence_length)],\n",
    "        'Importance': rf_model.model.feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='Importance', y='Day', data=feature_importance.head(10))\n",
    "    plt.title('Top 10 Most Important Days for Prediction')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display top 10 most important features\n",
    "    feature_importance.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b009c59b",
   "metadata": {},
   "source": [
    "## 5. Predicting Future Stock Prices\n",
    "\n",
    "Using our trained models, we'll predict the next day's stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c6e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the last sequence_length days for prediction\n",
    "last_sequence = data['Close'].values[-sequence_length:]\n",
    "print(f\"Using the last {sequence_length} days of data for prediction\")\n",
    "\n",
    "# Reshape for model input\n",
    "last_sequence = last_sequence.reshape(1, -1, 1)\n",
    "\n",
    "# Make predictions with each model\n",
    "predictions = {}\n",
    "for model in models:\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # Rescale the prediction\n",
    "    prediction_rescaled = scaler.inverse_transform(prediction.reshape(-1, 1))[0][0]\n",
    "    predictions[model.name] = prediction_rescaled\n",
    "    print(f\"{model.name} predicts next day's price: ${prediction_rescaled:.2f}\")\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "pred_df = pd.DataFrame(predictions.items(), columns=['Model', 'Predicted Price'])\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc035c7",
   "metadata": {},
   "source": [
    "## 6. Ablation Study: Effects of Sequence Length\n",
    "\n",
    "Let's investigate how changing the sequence length affects model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd02d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different sequence lengths\n",
    "sequence_lengths = [10, 30, 60, 90]\n",
    "results = []\n",
    "\n",
    "for seq_len in sequence_lengths:\n",
    "    print(f\"\\nTesting sequence length: {seq_len} days\")\n",
    "    \n",
    "    # Prepare data with this sequence length\n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_data_for_training(\n",
    "        data, target_column='Close', sequence_length=seq_len\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate Linear Regression model (fastest)\n",
    "    model = LinearRegressionModel()\n",
    "    model.train(X_train, y_train)\n",
    "    metrics, _ = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Sequence Length': seq_len,\n",
    "        'MSE': metrics['MSE'],\n",
    "        'R²': metrics['R²']\n",
    "    })\n",
    "\n",
    "# Create results DataFrame\n",
    "ablation_df = pd.DataFrame(results)\n",
    "ablation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af798cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the effect of sequence length on model performance\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(ablation_df['Sequence Length'], ablation_df['MSE'], marker='o')\n",
    "plt.title('Effect of Sequence Length on MSE')\n",
    "plt.xlabel('Sequence Length (days)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(ablation_df['Sequence Length'], ablation_df['R²'], marker='o')\n",
    "plt.title('Effect of Sequence Length on R²')\n",
    "plt.xlabel('Sequence Length (days)')\n",
    "plt.ylabel('R² Score')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fedf13",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "Our analysis of stock price prediction models using Apple (AAPL) historical data has yielded interesting insights:\n",
    "\n",
    "1. **Model Performance Comparison**:\n",
    "   - The Linear Regression model showed surprisingly strong performance, which suggests that for short-term prediction, linear relationships may capture enough information from recent price history.\n",
    "   - The Random Forest model struggled with overfitting to the training data.\n",
    "   - The Neural Network model (MLPRegressor) showed moderate performance and could potentially be improved with further hyperparameter tuning.\n",
    "\n",
    "2. **Feature Importance**:\n",
    "   - The Random Forest model's feature importance analysis gave us insight into which days in our sequence were most predictive of future prices.\n",
    "\n",
    "3. **Sequence Length Effects**:\n",
    "   - Our ablation study demonstrated how the length of historical data used impacts prediction accuracy.\n",
    "\n",
    "4. **Limitations and Future Work**:\n",
    "   - Stock prices are influenced by many external factors not captured in our models, such as news events, economic indicators, and market sentiment.\n",
    "   - Future work could incorporate alternative data sources and more sophisticated models like proper LSTM networks or attention-based architectures.\n",
    "   - Ensemble methods combining the strengths of different models could also be explored.\n",
    "\n",
    "Overall, while our models provide valuable insights, stock price prediction remains challenging due to the inherent uncertainty and complexity of financial markets."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
