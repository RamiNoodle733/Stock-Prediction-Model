{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4904d7b1",
   "metadata": {},
   "source": [
    "# Stock Market Data Exploration\n",
    "\n",
    "This notebook explores the characteristics of stock market data, examines statistical properties, and visualizes patterns that might be useful for prediction tasks.\n",
    "\n",
    "**Contents:**\n",
    "1. Data Loading and Initial Examination\n",
    "2. Statistical Analysis of Stock Prices\n",
    "3. Correlation Analysis\n",
    "4. Time Series Characteristics\n",
    "5. Feature Engineering Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43be45ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c086bc",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Examination\n",
    "\n",
    "We'll load a few sample stocks from our dataset and examine their basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa992d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data paths\n",
    "raw_data_path = '../data/raw/'\n",
    "\n",
    "# List available CSV files\n",
    "csv_files = [f for f in os.listdir(raw_data_path) if f.endswith('.csv')]\n",
    "print(f\"Found {len(csv_files)} stock data files.\")\n",
    "\n",
    "# Select a few well-known stocks to analyze\n",
    "sample_stocks = ['AAPL.csv', 'MSFT.csv', 'AMZN.csv', 'GOOG.csv']\n",
    "available_samples = [s for s in sample_stocks if s in csv_files]\n",
    "\n",
    "if not available_samples:\n",
    "    # If our preferred stocks aren't available, take the first few from the list\n",
    "    available_samples = csv_files[:4] if len(csv_files) >= 4 else csv_files\n",
    "\n",
    "print(f\"Selected stocks for analysis: {[os.path.splitext(s)[0] for s in available_samples]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stock data into DataFrames\n",
    "stock_data = {}\n",
    "for stock_file in available_samples:\n",
    "    symbol = os.path.splitext(stock_file)[0]\n",
    "    file_path = os.path.join(raw_data_path, stock_file)\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # If the date is in the index, reset it to be a column\n",
    "        if 'Date' not in df.columns and df.index.name == 'Date':\n",
    "            df = df.reset_index()\n",
    "        \n",
    "        # Ensure Date column is datetime\n",
    "        if 'Date' in df.columns:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "        \n",
    "        stock_data[symbol] = df\n",
    "        print(f\"Loaded {len(df)} rows for {symbol}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {symbol}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of one stock\n",
    "if stock_data:\n",
    "    symbol = list(stock_data.keys())[0]\n",
    "    print(f\"Sample data for {symbol}:\")\n",
    "    display(stock_data[symbol].head())\n",
    "    \n",
    "    # Data summary\n",
    "    print(f\"\\nSummary statistics for {symbol}:\")\n",
    "    display(stock_data[symbol].describe())\n",
    "    \n",
    "    # Check for missing values\n",
    "    missing_values = stock_data[symbol].isnull().sum()\n",
    "    print(f\"\\nMissing values in {symbol} data:\")\n",
    "    display(missing_values[missing_values > 0] if any(missing_values > 0) else \"No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3fb505",
   "metadata": {},
   "source": [
    "## 2. Statistical Analysis of Stock Prices\n",
    "\n",
    "Let's examine the distribution and statistical properties of stock prices and returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_returns(df):\n",
    "    \"\"\"Calculate daily and cumulative returns for a stock DataFrame.\"\"\"\n",
    "    df = df.copy()\n",
    "    df['Daily_Return'] = df['Close'].pct_change()\n",
    "    df['Cum_Return'] = (1 + df['Daily_Return']).cumprod() - 1\n",
    "    return df\n",
    "\n",
    "# Process all stocks\n",
    "for symbol, df in stock_data.items():\n",
    "    stock_data[symbol] = calculate_returns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c669c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the closing prices\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for symbol, df in stock_data.items():\n",
    "    plt.plot(df['Date'], df['Close'], label=symbol)\n",
    "\n",
    "plt.title('Historical Closing Prices', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Price (USD)', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily returns\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, (symbol, df) in enumerate(stock_data.items(), 1):\n",
    "    plt.subplot(len(stock_data), 1, i)\n",
    "    plt.plot(df['Date'], df['Daily_Return'], label=f'{symbol} Daily Returns')\n",
    "    plt.title(f'{symbol} Daily Returns', fontsize=14)\n",
    "    plt.grid(True)\n",
    "    if i == len(stock_data):  # Only add xlabel to the bottom subplot\n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Return', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare return distributions\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for symbol, df in stock_data.items():\n",
    "    sns.histplot(df['Daily_Return'].dropna(), kde=True, label=symbol, alpha=0.6)\n",
    "\n",
    "plt.title('Distribution of Daily Returns', fontsize=16)\n",
    "plt.xlabel('Daily Return', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb188b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics for returns\n",
    "returns_stats = {}\n",
    "\n",
    "for symbol, df in stock_data.items():\n",
    "    returns = df['Daily_Return'].dropna()\n",
    "    \n",
    "    stats = {\n",
    "        'Mean': returns.mean(),\n",
    "        'Median': returns.median(),\n",
    "        'Std Dev': returns.std(),\n",
    "        'Min': returns.min(),\n",
    "        'Max': returns.max(),\n",
    "        'Skewness': returns.skew(),\n",
    "        'Kurtosis': returns.kurt(),  # Excess kurtosis (normal = 0)\n",
    "        '% Positive Days': (returns > 0).mean() * 100\n",
    "    }\n",
    "    \n",
    "    returns_stats[symbol] = stats\n",
    "\n",
    "# Display as DataFrame\n",
    "stats_df = pd.DataFrame(returns_stats).T\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2405b",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis\n",
    "\n",
    "We'll examine correlations between different stocks and different features of the same stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with returns from all stocks\n",
    "returns_df = pd.DataFrame({\n",
    "    symbol: df['Daily_Return'] for symbol, df in stock_data.items()\n",
    "})\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = returns_df.corr()\n",
    "\n",
    "# Plot correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix of Stock Returns', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75406280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine correlations between different features for a single stock\n",
    "if stock_data:\n",
    "    symbol = list(stock_data.keys())[0]\n",
    "    features = ['Open', 'High', 'Low', 'Close', 'Volume', 'Daily_Return']\n",
    "    \n",
    "    # Select available features\n",
    "    available_features = [f for f in features if f in stock_data[symbol].columns]\n",
    "    feature_df = stock_data[symbol][available_features]\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    feature_corr = feature_df.corr()\n",
    "    \n",
    "    # Plot correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(feature_corr, annot=True, cmap='coolwarm', linewidths=0.5, vmin=-1, vmax=1)\n",
    "    plt.title(f'Feature Correlation Matrix for {symbol}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615b7d5",
   "metadata": {},
   "source": [
    "## 4. Time Series Characteristics\n",
    "\n",
    "Now let's explore the time series properties of stock prices, including:\n",
    "- Stationarity tests\n",
    "- Autocorrelation analysis\n",
    "- Seasonality detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b50f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(series, window=30, title=''):\n",
    "    \"\"\"Check stationarity of a time series using the ADF test and rolling statistics.\"\"\"\n",
    "    # Calculate rolling statistics\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "    rolling_std = series.rolling(window=window).std()\n",
    "    \n",
    "    # Plot rolling statistics\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(series, label='Original')\n",
    "    plt.plot(rolling_mean, label=f'Rolling Mean ({window} days)')\n",
    "    plt.plot(rolling_std, label=f'Rolling Std ({window} days)')\n",
    "    plt.title(f'Rolling Statistics - {title}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ADF test\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'ADF Statistic: {result[0]:.4f}')\n",
    "    print(f'p-value: {result[1]:.4f}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value:.4f}')\n",
    "    \n",
    "    # Interpret results\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Result: The series is stationary (reject the null hypothesis)\")\n",
    "    else:\n",
    "        print(\"Result: The series is non-stationary (fail to reject the null hypothesis)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check stationarity of price and returns for a sample stock\n",
    "if stock_data:\n",
    "    symbol = list(stock_data.keys())[0]\n",
    "    \n",
    "    # Check price stationarity\n",
    "    print(f\"\\nStationarity Test for {symbol} Closing Prices:\\n{'-'*40}\")\n",
    "    check_stationarity(stock_data[symbol]['Close'], title=f'{symbol} Closing Prices')\n",
    "    \n",
    "    # Check returns stationarity\n",
    "    print(f\"\\nStationarity Test for {symbol} Daily Returns:\\n{'-'*40}\")\n",
    "    check_stationarity(stock_data[symbol]['Daily_Return'].dropna(), title=f'{symbol} Daily Returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0c7062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot autocorrelation and partial autocorrelation for returns\n",
    "if stock_data:\n",
    "    symbol = list(stock_data.keys())[0]\n",
    "    returns = stock_data[symbol]['Daily_Return'].dropna()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot ACF\n",
    "    plot_acf(returns, ax=axes[0], lags=30)\n",
    "    axes[0].set_title(f'Autocorrelation Function (ACF) - {symbol} Returns', fontsize=14)\n",
    "    \n",
    "    # Plot PACF\n",
    "    plot_pacf(returns, ax=axes[1], lags=30)\n",
    "    axes[1].set_title(f'Partial Autocorrelation Function (PACF) - {symbol} Returns', fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31ed060",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering Exploration\n",
    "\n",
    "Let's explore some common feature engineering techniques for stock price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for stock price prediction.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Moving averages\n",
    "    for window in [5, 10, 20, 50]:\n",
    "        df[f'Close_MA_{window}'] = df['Close'].rolling(window=window).mean()\n",
    "    \n",
    "    # Price momentum (percentage change over window)\n",
    "    for window in [5, 10, 20]:\n",
    "        df[f'Momentum_{window}'] = df['Close'].pct_change(periods=window)\n",
    "    \n",
    "    # Volatility (standard deviation over window)\n",
    "    for window in [5, 10, 20]:\n",
    "        df[f'Volatility_{window}'] = df['Close'].rolling(window=window).std()\n",
    "    \n",
    "    # Trading volume features\n",
    "    if 'Volume' in df.columns:\n",
    "        df['Volume_Change'] = df['Volume'].pct_change()\n",
    "        df['Volume_MA_5'] = df['Volume'].rolling(window=5).mean()\n",
    "    \n",
    "    # High-Low range\n",
    "    if 'High' in df.columns and 'Low' in df.columns:\n",
    "        df['HL_PCT'] = (df['High'] - df['Low']) / df['Close'] * 100.0\n",
    "    \n",
    "    # Day of week\n",
    "    if 'Date' in df.columns:\n",
    "        df['Day_of_Week'] = df['Date'].dt.dayofweek\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Engineer features for the first stock\n",
    "if stock_data:\n",
    "    symbol = list(stock_data.keys())[0]\n",
    "    engineered_df = engineer_features(stock_data[symbol])\n",
    "    \n",
    "    # Display the new features\n",
    "    print(f\"Engineered features for {symbol}:\")\n",
    "    display(engineered_df.columns.tolist())\n",
    "    \n",
    "    # Display a sample of the engineered data\n",
    "    display(engineered_df.iloc[50:55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some of the engineered features\n",
    "if 'engineered_df' in locals():\n",
    "    # Plot close price and moving averages\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    plt.plot(engineered_df['Date'], engineered_df['Close'], label='Close Price')\n",
    "    \n",
    "    for window in [5, 20, 50]:\n",
    "        plt.plot(engineered_df['Date'], \n",
    "                engineered_df[f'Close_MA_{window}'], \n",
    "                label=f'{window}-day MA', \n",
    "                alpha=0.7)\n",
    "    \n",
    "    plt.title(f'{symbol} - Price and Moving Averages', fontsize=16)\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "    plt.ylabel('Price', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11569d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot volatility over time\n",
    "if 'engineered_df' in locals():\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    \n",
    "    for window in [5, 10, 20]:\n",
    "        plt.plot(engineered_df['Date'], \n",
    "                engineered_df[f'Volatility_{window}'], \n",
    "                label=f'{window}-day Volatility')\n",
    "    \n",
    "    plt.title(f'{symbol} - Price Volatility', fontsize=16)\n",
    "    plt.xlabel('Date', fontsize=14)\n",
    "    plt.ylabel('Standard Deviation', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbd2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature correlations with future returns\n",
    "if 'engineered_df' in locals():\n",
    "    # Create future returns (target variable)\n",
    "    for days in [1, 5, 10]:\n",
    "        engineered_df[f'Future_Return_{days}d'] = engineered_df['Close'].pct_change(periods=days).shift(-days)\n",
    "    \n",
    "    # Select features and target\n",
    "    features = [col for col in engineered_df.columns \n",
    "               if col not in ['Date', 'Future_Return_1d', 'Future_Return_5d', 'Future_Return_10d']]\n",
    "    \n",
    "    # Calculate correlations\n",
    "    correlations = {}\n",
    "    for days in [1, 5, 10]:\n",
    "        target = f'Future_Return_{days}d'\n",
    "        corr_series = engineered_df[features].corrwith(engineered_df[target]).sort_values(ascending=False)\n",
    "        correlations[target] = corr_series\n",
    "    \n",
    "    # Display top correlations\n",
    "    for target, corrs in correlations.items():\n",
    "        print(f\"\\nTop correlations with {target}:\")\n",
    "        display(corrs.head(10))\n",
    "        print(f\"Bottom correlations with {target}:\")\n",
    "        display(corrs.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e2775",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored the characteristics of stock market data, examining statistical properties, time-series behaviors, correlations, and potential predictive features. \n",
    "\n",
    "Key findings:\n",
    "1. Stock prices are typically non-stationary, while returns tend to be stationary\n",
    "2. There are correlations between stocks in similar sectors\n",
    "3. Various engineered features show different levels of correlation with future returns\n",
    "\n",
    "The insights from this exploratory analysis will inform our feature engineering and modeling approaches in the subsequent notebooks."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
